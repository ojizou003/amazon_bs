{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoupとseleniumを使ってamazonをスクレイピング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# キーワードと検索するページ数の設定\n",
    "keyword = 'スクレイピング'\n",
    "num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import csv\n",
    "import datetime\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検索結果の初期ページ\n",
    "driver_path = ChromeDriverManager().install()\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "service = Service(executable_path=driver_path)\n",
    "\n",
    "browser = webdriver.Chrome(options=options, service=service)\n",
    "browser.implicitly_wait(10)\n",
    "browser.get('http://amazon.co.jp/')\n",
    "browser.implicitly_wait(10)\n",
    "search = browser.find_element(By.ID, 'twotabsearchtextbox')\n",
    "browser.implicitly_wait(10)\n",
    "search.send_keys(keyword)\n",
    "browser.implicitly_wait(10)\n",
    "search.submit()\n",
    "browser.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = np.arange(1, num + 1)\n",
    "all_item_name = []\n",
    "all_price = []\n",
    "all_image = []\n",
    "all_link = []\n",
    "\n",
    "for p in pages:\n",
    "\n",
    "    # urlの取得\n",
    "    url = browser.execute_script(\"return window.location.href\")\n",
    "    browser.implicitly_wait(10)\n",
    "\n",
    "    # ダミーのヘッダー情報を使ってsoupを取得\n",
    "    hdr = {\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "        'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "        'Accept-Encoding': 'none',\n",
    "        'Accept-Language': 'ja-JP,en-US;q=0.7,en-GB;q=0.3',\n",
    "        'Connection': 'keep-alive'} #ダミーのヘッダー情報\n",
    "    req = Request(url, headers=hdr)\n",
    "    sleep(1)\n",
    "\n",
    "    page = urlopen(req)\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    items = soup.find_all('div', {'class': 'puis-card-container'})\n",
    "    item_name_list = []\n",
    "    price_list = []\n",
    "    image_list = []\n",
    "    link_list = []\n",
    "    for i in range(len(items)):\n",
    "        if items[i].find_all('span', {'class': 'a-price-whole'}):\n",
    "            price = int(items[i].find('span', {'class': 'a-price-whole'}).text.replace(',', ''))\n",
    "            price_list.append(price)\n",
    "            try:\n",
    "                item_name_list.append(items[i].find_all('span', {'class': 'a-size-base-plus'})[1].text)\n",
    "            except:\n",
    "                item_name_list.append(items[i].find_all('span', {'class': 'a-size-base-plus'})[0].text)\n",
    "            try:\n",
    "                image_list.append(items[i].find('img', {'class': 's-image s-image-optimized-rendering'}).get('src'))\n",
    "            except:\n",
    "                image_list.append('[画像なし]')\n",
    "            try:\n",
    "                href = items[i].find('a', {'class': 'a-link-normal'}).get('href')\n",
    "                link = f'https://amazon.co.jp{href}'\n",
    "                link_list.append(link)\n",
    "            except:\n",
    "                link_list.append('[詳細ページなし]')\n",
    "        else:\n",
    "            pass\n",
    "    all_item_name.extend(item_name_list)\n",
    "    all_price.extend(price_list)\n",
    "    all_image.extend(image_list)\n",
    "    all_link.extend(link_list)\n",
    "    browser.find_element(By.LINK_TEXT, '次へ').click()\n",
    "    browser.implicitly_wait(10)\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excelへ出力\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "japan_tz = pytz.timezone('Asia/Tokyo')\n",
    "japan_now = datetime.now(japan_tz)\n",
    "today = japan_now.strftime('%Y%m%d')\n",
    "\n",
    "count = np.arange(len(all_image))\n",
    "img_func = [f'=image(C{c+2})' for c in count]\n",
    "link_func = [f'=hyperlink(E{c+2})' for c in count]\n",
    "\n",
    "df =pd.DataFrame(columns=['item', 'price', 'image_url', 'image', 'link_o', 'link'])\n",
    "df['item'] = all_item_name\n",
    "df['price'] = all_price\n",
    "df['image_url'] = all_image\n",
    "df['image'] = img_func\n",
    "df['link_o'] = all_link\n",
    "df['link'] = link_func\n",
    "df.to_excel(f'{keyword}{today}.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
